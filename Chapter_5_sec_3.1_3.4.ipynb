{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.3 Lab: Cross-Validation and the Bootstrap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3.1 The Validation Set Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/qiuping1/anaconda2/lib/python2.7/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import pandas as pd \n",
    "import math\n",
    "import random\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.graphics.regressionplots import *\n",
    "from sklearn import datasets, linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(392, 9)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "Auto = pd.read_csv('data/Auto.csv', header=0, na_values='?')\n",
    "Auto = Auto.dropna().reset_index(drop=True) # drop the observation with NA values and reindex the obs from 0\n",
    "Auto.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python and R use different random number generator, so we may see slightly difference results in this chapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "train = np.random.choice(Auto.shape[0], 196, replace=False)\n",
    "select = np.in1d(range(Auto.shape[0]), train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                    mpg   R-squared:                       0.620\n",
      "Model:                            OLS   Adj. R-squared:                  0.618\n",
      "Method:                 Least Squares   F-statistic:                     316.4\n",
      "Date:                Wed, 08 Mar 2017   Prob (F-statistic):           1.28e-42\n",
      "Time:                        16:58:23   Log-Likelihood:                -592.07\n",
      "No. Observations:                 196   AIC:                             1188.\n",
      "Df Residuals:                     194   BIC:                             1195.\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept     40.3338      1.023     39.416      0.000      38.316      42.352\n",
      "horsepower    -0.1596      0.009    -17.788      0.000      -0.177      -0.142\n",
      "==============================================================================\n",
      "Omnibus:                        8.393   Durbin-Watson:                   1.061\n",
      "Prob(Omnibus):                  0.015   Jarque-Bera (JB):                8.787\n",
      "Skew:                           0.516   Prob(JB):                       0.0124\n",
      "Kurtosis:                       2.899   Cond. No.                         328.\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "--------Test Error for 1st order--------\n",
      "23.3619028926\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "lm = smf.ols ('mpg~horsepower', data = Auto[select]).fit()\n",
    "print lm.summary()\n",
    "preds = lm.predict(Auto)\n",
    "square_error = (Auto['mpg'] - preds)**2\n",
    "print '--------Test Error for 1st order--------'\n",
    "print np.mean(square_error[~select])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------Test Error for 2nd order--------\n",
      "20.2526908584\n"
     ]
    }
   ],
   "source": [
    "lm2 = smf.ols ('mpg~horsepower + I(horsepower ** 2.0)', data = Auto[select]).fit()\n",
    "preds = lm2.predict(Auto)\n",
    "square_error = (Auto['mpg'] - preds)**2\n",
    "print '--------Test Error for 2nd order--------'\n",
    "print np.mean(square_error[~select])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------Test Error for 3rd order--------\n",
      "20.3256093659\n"
     ]
    }
   ],
   "source": [
    "lm3 = smf.ols ('mpg~horsepower + I(horsepower ** 2.0) + I(horsepower ** 3.0)', data = Auto[select]).fit()\n",
    "preds = lm3.predict(Auto)\n",
    "square_error = (Auto['mpg'] - preds)**2\n",
    "print '--------Test Error for 3rd order--------'\n",
    "print np.mean(square_error[~select])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### These results are consistent with our previous findings: a model that predicts mpg using a quadratic function of horsepower performs better than a model that involves only a linear function of horsepower, and there is little evidence in favor of a model that uses a cubic function of horsepower."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If we look at the summmary for 3rd order regression, the coefficient of the 3rd order term is not statistically significant. I will use this as Supporting evidence for the above claim. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                    mpg   R-squared:                       0.722\n",
      "Model:                            OLS   Adj. R-squared:                  0.717\n",
      "Method:                 Least Squares   F-statistic:                     165.9\n",
      "Date:                Wed, 08 Mar 2017   Prob (F-statistic):           4.60e-53\n",
      "Time:                        16:58:23   Log-Likelihood:                -561.56\n",
      "No. Observations:                 196   AIC:                             1131.\n",
      "Df Residuals:                     192   BIC:                             1144.\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "========================================================================================\n",
      "                           coef    std err          t      P>|t|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------------\n",
      "Intercept               66.5200      6.310     10.541      0.000      54.073      78.967\n",
      "horsepower              -0.6868      0.162     -4.238      0.000      -1.006      -0.367\n",
      "I(horsepower ** 2.0)     0.0028      0.001      2.157      0.032       0.000       0.005\n",
      "I(horsepower ** 3.0) -3.524e-06   3.27e-06     -1.078      0.282   -9.97e-06    2.92e-06\n",
      "==============================================================================\n",
      "Omnibus:                        9.054   Durbin-Watson:                   1.328\n",
      "Prob(Omnibus):                  0.011   Jarque-Bera (JB):               15.936\n",
      "Skew:                           0.174   Prob(JB):                     0.000346\n",
      "Kurtosis:                       4.353   Cond. No.                     5.83e+07\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 5.83e+07. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "print lm3.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3.2 Leave-One-Out Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OLS Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept     39.935861\n",
      "horsepower    -0.157845\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "ols_fit = smf.ols ('mpg~horsepower', data = Auto).fit()\n",
    "print ols_fit.params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GLM Fit. Compare with OLS fit, the coeffs are the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept     39.935861\n",
      "horsepower    -0.157845\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "glm_fit = sm.GLM.from_formula('mpg~horsepower', data = Auto).fit()\n",
    "print glm_fit.params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying CV in Python is not as easy as that in R. It will require some manual coding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To use some of implemented function in Python, we use Sklearn for linear model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39.9358610212\n",
      "[-0.15784473]\n"
     ]
    }
   ],
   "source": [
    "x = pd.DataFrame(Auto.horsepower)\n",
    "y = Auto.mpg\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(x, y)\n",
    "print model.intercept_\n",
    "print model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24.2315135179\n"
     ]
    }
   ],
   "source": [
    "k_fold = KFold(n_splits=x.shape[0]) # loo use folds equal to # of observations\n",
    "test = cross_val_score(model, x, y, cv=k_fold,  scoring = 'neg_mean_squared_error', n_jobs=-1)\n",
    "print np.mean(-test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For higher order polynomial fit, we use pipline tool. Below shows how to fit an order 1 to 5 polynomial data and show the loo results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[24.231513517929226, 19.248213124490029, 19.334984064022926, 19.424430301371874, 19.033232559685043]\n"
     ]
    }
   ],
   "source": [
    "A = []\n",
    "for porder in xrange(1, 6):\n",
    "    model = Pipeline([('poly', PolynomialFeatures(degree=porder)), ('linear', LinearRegression(fit_intercept=False))])\n",
    "    k_fold = KFold(n_splits=x.shape[0]) # loo use folds equal to # of observations\n",
    "    test = cross_val_score(model, x, y, cv=k_fold,  scoring = 'neg_mean_squared_error', n_jobs=-1)\n",
    "    A.append(np.mean(-test))\n",
    "    \n",
    "print A"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
